{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Restaurant Inspection & Yelp Review Analysis\n",
        "\n",
        "This notebook demonstrates the complete workflow for analyzing restaurant inspection data and Yelp reviews using machine learning models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Import custom modules\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "from preprocess import clean_inspection_data, clean_text, match_inspection_to_reviews\n",
        "from modeling import ModelTrainer, split_data\n",
        "from evaluation import evaluate_all_models, plot_confusion_matrix, compare_models\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "print('Libraries imported successfully!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load inspection data\n",
        "df_inspection = pd.read_csv('../data/Final_Inspection_Data.csv')\n",
        "\n",
        "# Load recent inspection data\n",
        "df_recent = pd.read_csv('../data/RecentInspDate.csv')\n",
        "\n",
        "print(f'Inspection data shape: {df_inspection.shape}')\n",
        "print(f'Recent inspection data shape: {df_recent.shape}')\n",
        "\n",
        "df_inspection.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display basic statistics\n",
        "print('\\nData Info:')\n",
        "df_inspection.info()\n",
        "\n",
        "print('\\nNumerical Summary:')\n",
        "df_inspection.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize grade distribution\n",
        "if 'GRADE' in df_inspection.columns:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    df_inspection['GRADE'].value_counts().plot(kind='bar')\n",
        "    plt.title('Distribution of Restaurant Grades')\n",
        "    plt.xlabel('Grade')\n",
        "    plt.ylabel('Count')\n",
        "    plt.xticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../figures/grade_distribution.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize score distribution\n",
        "if 'SCORE' in df_inspection.columns:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    df_inspection['SCORE'].dropna().hist(bins=30, edgecolor='black')\n",
        "    plt.title('Distribution of Inspection Scores')\n",
        "    plt.xlabel('Score')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../figures/score_distribution.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean violation descriptions\n",
        "if 'VIOLATION DESCRIPTION' in df_inspection.columns:\n",
        "    df_inspection['violation_clean'] = df_inspection['VIOLATION DESCRIPTION'].apply(clean_text)\n",
        "    print('Text cleaning completed!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for modeling\n",
        "# Filter data with grades\n",
        "df_model = df_inspection[df_inspection['GRADE'].notna()].copy()\n",
        "\n",
        "# Create binary classification: A vs Not A\n",
        "df_model['grade_binary'] = (df_model['GRADE'] == 'A').astype(int)\n",
        "\n",
        "print(f'Modeling dataset shape: {df_model.shape}')\n",
        "print(f'\\nClass distribution:')\n",
        "print(df_model['grade_binary'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize model trainer\n",
        "trainer = ModelTrainer(random_state=42)\n",
        "\n",
        "# Prepare features\n",
        "X_text = df_model['violation_clean'].fillna('')\n",
        "y = df_model['grade_binary']\n",
        "\n",
        "# Vectorize text\n",
        "X = trainer.prepare_features(X_text)\n",
        "\n",
        "print(f'Feature matrix shape: {X.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = split_data(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f'Training set size: {X_train.shape[0]}')\n",
        "print(f'Test set size: {X_test.shape[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train all models\n",
        "models = trainer.train_all_models(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate all models\n",
        "results = evaluate_all_models(models, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare models\n",
        "df_comparison = compare_models(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot confusion matrices\n",
        "for name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    plot_confusion_matrix(\n",
        "        y_test, \n",
        "        y_pred, \n",
        "        labels=['Not A', 'A'],\n",
        "        title=f'Confusion Matrix - {name.replace(\"_\", \" \").title()}',\n",
        "        save_path=f'../figures/confusion_matrix_{name}.png'\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('\\n' + '='*80)\n",
        "print('FINAL RESULTS SUMMARY')\n",
        "print('='*80)\n",
        "print(df_comparison.to_string())\n",
        "print('\\nBest performing model:', df_comparison.index[0])\n",
        "print(f'F1 Score: {df_comparison.iloc[0][\"f1_score\"]:.4f}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}